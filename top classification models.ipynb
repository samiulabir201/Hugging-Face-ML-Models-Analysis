{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPZI61vCKf0Z","executionInfo":{"status":"ok","timestamp":1703059651859,"user_tz":-360,"elapsed":5180,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"0b907eef-b254-47b2-c131-b343b363f214"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","source":["# obtain a list of the top-20 \"Text Classification\" and top-20 \"Text Generation\" models on https://huggingface.co/, ranked based on popularity"],"metadata":{"id":"-2I8u_avPKTx"}},{"cell_type":"code","source":["import csv\n","from huggingface_hub import HfApi\n","\n","# Function to get all models with a specific tag\n","def get_models_by_tag(tag):\n","    hf_api = HfApi(endpoint=\"https://huggingface.co\")\n","    all_models = hf_api.list_models()\n","    tag_models = [model for model in all_models if tag.lower() in [model_tag.lower() for model_tag in model.tags]]\n","    return tag_models\n","\n","# Get all \"text classification\" models\n","text_classification_models = get_models_by_tag(\"text-classification\")\n","\n","# Sort models by downloads in descending order\n","text_classification_models_sorted = sorted(text_classification_models, key=lambda x: x.downloads, reverse=True)\n","\n","# Prepare data for CSV\n","csv_data = [[\"Rank\", \"Model ID\", \"Downloads\"]]\n","for i, model in enumerate(text_classification_models_sorted[:20]):\n","    csv_data.append([i + 1, model.modelId, model.downloads])\n","\n","# Save to CSV file\n","csv_file_path = \"top_text_classification_models.csv\"\n","with open(csv_file_path, mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(csv_data)\n","\n","print(f\"CSV file saved at: {csv_file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jsNpARwzjm8e","executionInfo":{"status":"ok","timestamp":1703059693321,"user_tz":-360,"elapsed":41465,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"8507d176-3cd5-498b-9b6f-e11c1cad190a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file saved at: top_text_classification_models.csv\n"]}]},{"cell_type":"markdown","source":[" # obtain and compare the number of ML apps (\"spaces\") for each \"Text Classification\" and \"Text Generation\" model obtained in step 1"],"metadata":{"id":"xIuMe15iPekQ"}},{"cell_type":"code","source":["!pip install requests\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"np8bVzSawcN1","executionInfo":{"status":"ok","timestamp":1703059697714,"user_tz":-360,"elapsed":4406,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"bd858ff3-d45e-4db9-fcc9-91cb99d45889"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n"]}]},{"cell_type":"code","source":["!pip install requests beautifulsoup4\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1FoacxtWG-F","executionInfo":{"status":"ok","timestamp":1703059702358,"user_tz":-360,"elapsed":4647,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"cb51f353-e4f9-436a-be78-598a069cac0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"eK4KP194Ps2N"}},{"cell_type":"markdown","source":["## obtain and compare the number of ML apps (\"spaces\") for each \"Text Classification\""],"metadata":{"id":"whNCB1v_PwvA"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","\n","# Function to get the number of articles for a model\n","def get_num_articles(classification_model_name):\n","    url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    response = requests.get(url)\n","\n","    if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","        try:\n","            html_content = response.text\n","            soup = BeautifulSoup(html_content, 'html.parser')\n","\n","            # Find the div with class \"grid grid-cols-1 gap-x-4 gap-y-6 md:grid-cols-3 xl:grid-cols-4\"\n","            class_div = soup.find('div', class_='grid grid-cols-1 gap-x-4 gap-y-6 md:grid-cols-3 xl:grid-cols-4')\n","\n","            if class_div:\n","                # Find all articles under the div\n","                articles = class_div.find_all('article', class_='')\n","\n","                # Return the number of articles\n","                return len(articles)\n","            else:\n","                return 0\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            return 0\n","    else:\n","        print(f\"Error: {response.status_code} - {response.text}\")\n","        return 0\n","\n","# Function to get all models with a specific tag\n","def get_models_by_tag(tag):\n","    hf_api = HfApi(endpoint=\"https://huggingface.co\")\n","    all_models = hf_api.list_models()\n","    tag_models = [model for model in all_models if tag.lower() in [model_tag.lower() for model_tag in model.tags]]\n","    return tag_models\n","\n","# Get all \"text classification\" models\n","text_classification_models = get_models_by_tag(\"text-classification\")\n","\n","# Sort models by downloads in descending order\n","text_classification_models_sorted = sorted(text_classification_models, key=lambda x: x.downloads, reverse=True)\n","\n","# Save model names in an array\n","classification_model_names = []\n","\n","# Display information about \"text classification\" models and get the number of articles for each model\n","for i, model in enumerate(text_classification_models_sorted[:20]):\n","    classification_model_names.append(model.modelId)\n","    modified_url = f\"https://huggingface.co/spaces?sort=likes&search={model.modelId}\"\n","\n","    # Fetch the number of articles for the current model\n","    num_articles = get_num_articles(model.modelId)\n","\n","    print(f\"{i+1}. {model.modelId} - Downloads: {model.downloads}\")\n","    print(f\"   Tags: {', '.join(model.tags)}\")\n","    print(f\"   Last Modified: {model.lastModified}\")\n","    print(f\"   Number of apps: {num_articles}\\n\")\n","\n","# Now model_names contains the names of the first 10 text classification models\n","print(\"Model names array:\", classification_model_names)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_S7wVVPGhu_t","executionInfo":{"status":"ok","timestamp":1703061289489,"user_tz":-360,"elapsed":39721,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"26e9d0e5-f7df-430f-9b51-896f4dd58413"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. distilbert-base-uncased-finetuned-sst-2-english - Downloads: 8486425\n","   Tags: transformers, pytorch, tf, rust, onnx, safetensors, distilbert, text-classification, en, dataset:sst2, dataset:glue, arxiv:1910.01108, doi:10.57967/hf/0181, license:apache-2.0, model-index, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 16\n","\n","2. cardiffnlp/twitter-roberta-base-irony - Downloads: 7177328\n","   Tags: transformers, pytorch, tf, jax, roberta, text-classification, en, dataset:tweet_eval, arxiv:2010.12421, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 2\n","\n","3. lxyuan/distilbert-base-multilingual-cased-sentiments-student - Downloads: 7053643\n","   Tags: transformers, pytorch, safetensors, distilbert, text-classification, sentiment-analysis, zero-shot-distillation, distillation, zero-shot-classification, debarta-v3, en, ar, de, es, fr, ja, zh, id, hi, it, ms, pt, dataset:tyqiangz/multilingual-sentiments, doi:10.57967/hf/1422, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","4. mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis - Downloads: 6684810\n","   Tags: transformers, pytorch, tensorboard, safetensors, roberta, text-classification, generated_from_trainer, financial, stocks, sentiment, dataset:financial_phrasebank, license:apache-2.0, model-index, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 2\n","\n","5. SamLowe/roberta-base-go_emotions - Downloads: 6671735\n","   Tags: transformers, pytorch, safetensors, roberta, text-classification, emotions, multi-class-classification, multi-label-classification, en, dataset:go_emotions, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 8\n","\n","6. marieke93/MiniLM-evidence-types - Downloads: 6601091\n","   Tags: transformers, pytorch, tensorboard, bert, text-classification, generated_from_trainer, license:mit, autotrain_compatible, endpoints_compatible, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","7. Ashishkr/query_wellformedness_score - Downloads: 6598340\n","   Tags: transformers, pytorch, jax, safetensors, roberta, text-classification, dataset:google_wellformed_query, license:apache-2.0, autotrain_compatible, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","8. MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli - Downloads: 5593478\n","   Tags: transformers, pytorch, safetensors, deberta-v2, text-classification, zero-shot-classification, en, dataset:multi_nli, dataset:anli, dataset:fever, arxiv:2006.03654, license:mit, model-index, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 3\n","\n","9. cardiffnlp/twitter-roberta-base-sentiment - Downloads: 3842624\n","   Tags: transformers, pytorch, tf, jax, roberta, text-classification, en, dataset:tweet_eval, arxiv:2010.12421, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","10. facebook/bart-large-mnli - Downloads: 2457417\n","   Tags: transformers, pytorch, jax, rust, safetensors, bart, text-classification, zero-shot-classification, dataset:multi_nli, arxiv:1910.13461, arxiv:1909.00161, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","11. cardiffnlp/twitter-roberta-base-sentiment-latest - Downloads: 2113872\n","   Tags: transformers, pytorch, tf, roberta, text-classification, en, dataset:tweet_eval, arxiv:2202.03829, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 19\n","\n","12. nlptown/bert-base-multilingual-uncased-sentiment - Downloads: 1659708\n","   Tags: transformers, pytorch, tf, jax, bert, text-classification, en, nl, de, fr, it, es, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 5\n","\n","13. cardiffnlp/twitter-xlm-roberta-base-sentiment - Downloads: 1440401\n","   Tags: transformers, pytorch, tf, xlm-roberta, text-classification, multilingual, arxiv:2104.12250, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 4\n","\n","14. papluca/xlm-roberta-base-language-detection - Downloads: 1158259\n","   Tags: transformers, pytorch, tf, safetensors, xlm-roberta, text-classification, generated_from_trainer, multilingual, ar, bg, de, el, en, es, fr, hi, it, ja, nl, pl, pt, ru, sw, th, tr, ur, vi, zh, arxiv:1911.02116, base_model:xlm-roberta-base, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","15. ProsusAI/finbert - Downloads: 951571\n","   Tags: transformers, pytorch, tf, jax, bert, text-classification, financial-sentiment-analysis, sentiment-analysis, en, arxiv:1908.10063, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 9\n","\n","16. cross-encoder/ms-marco-TinyBERT-L-2-v2 - Downloads: 916694\n","   Tags: transformers, pytorch, jax, bert, text-classification, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","17. cross-encoder/ms-marco-MiniLM-L-4-v2 - Downloads: 899146\n","   Tags: transformers, pytorch, jax, bert, text-classification, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","18. martin-ha/toxic-comment-model - Downloads: 828541\n","   Tags: transformers, pytorch, distilbert, text-classification, en, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","19. alexandrainst/scandi-nli-large - Downloads: 741649\n","   Tags: transformers, pytorch, safetensors, bert, text-classification, zero-shot-classification, da, no, nb, sv, dataset:strombergnlp/danfever, dataset:KBLab/overlim, dataset:MoritzLaurer/multilingual-NLI-26lang-2mil7, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","20. laiyer/deberta-v3-base-prompt-injection - Downloads: 690902\n","   Tags: transformers, onnx, safetensors, deberta-v2, text-classification, prompt-injection, injection, security, generated_from_trainer, en, dataset:Lakera/gandalf_ignore_instructions, dataset:rubend18/ChatGPT-Jailbreak-Prompts, dataset:imoxto/prompt_injection_cleaned_dataset-v2, dataset:hackaprompt/hackaprompt-dataset, dataset:fka/awesome-chatgpt-prompts, dataset:teven/prompted_examples, dataset:Dahoas/synthetic-hh-rlhf-prompts, dataset:Dahoas/hh_prompt_format, dataset:MohamedRashad/ChatGPT-prompts, dataset:HuggingFaceH4/instruction-dataset, dataset:HuggingFaceH4/no_robots, dataset:HuggingFaceH4/ultrachat_200k, base_model:microsoft/deberta-v3-base, license:apache-2.0, co2_eq_emissions, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","Model names array: ['distilbert-base-uncased-finetuned-sst-2-english', 'cardiffnlp/twitter-roberta-base-irony', 'lxyuan/distilbert-base-multilingual-cased-sentiments-student', 'mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis', 'SamLowe/roberta-base-go_emotions', 'marieke93/MiniLM-evidence-types', 'Ashishkr/query_wellformedness_score', 'MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli', 'cardiffnlp/twitter-roberta-base-sentiment', 'facebook/bart-large-mnli', 'cardiffnlp/twitter-roberta-base-sentiment-latest', 'nlptown/bert-base-multilingual-uncased-sentiment', 'cardiffnlp/twitter-xlm-roberta-base-sentiment', 'papluca/xlm-roberta-base-language-detection', 'ProsusAI/finbert', 'cross-encoder/ms-marco-TinyBERT-L-2-v2', 'cross-encoder/ms-marco-MiniLM-L-4-v2', 'martin-ha/toxic-comment-model', 'alexandrainst/scandi-nli-large', 'laiyer/deberta-v3-base-prompt-injection']\n"]}]},{"cell_type":"markdown","source":["## csv for classification model"],"metadata":{"id":"zIrKbNmfRzi5"}},{"cell_type":"code","source":["print(classification_model_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"in0A-8EtwVNp","executionInfo":{"status":"ok","timestamp":1703059895072,"user_tz":-360,"elapsed":866,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"86358aa3-dd8e-4d34-d9c0-0b17338f8773"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['distilbert-base-uncased-finetuned-sst-2-english', 'cardiffnlp/twitter-roberta-base-irony', 'lxyuan/distilbert-base-multilingual-cased-sentiments-student', 'mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis', 'SamLowe/roberta-base-go_emotions', 'marieke93/MiniLM-evidence-types', 'Ashishkr/query_wellformedness_score', 'MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli', 'cardiffnlp/twitter-roberta-base-sentiment', 'facebook/bart-large-mnli', 'cardiffnlp/twitter-roberta-base-sentiment-latest', 'nlptown/bert-base-multilingual-uncased-sentiment', 'cardiffnlp/twitter-xlm-roberta-base-sentiment', 'papluca/xlm-roberta-base-language-detection', 'ProsusAI/finbert', 'cross-encoder/ms-marco-TinyBERT-L-2-v2', 'cross-encoder/ms-marco-MiniLM-L-4-v2', 'martin-ha/toxic-comment-model', 'alexandrainst/scandi-nli-large', 'laiyer/deberta-v3-base-prompt-injection']\n"]}]},{"cell_type":"markdown","source":["### Classification model: mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis"],"metadata":{"id":"h26mo_qYglS-"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis \"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps4.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qgi-MOAS-q7","executionInfo":{"status":"ok","timestamp":1703062138038,"user_tz":-360,"elapsed":100255,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"d383d41b-cee6-4c4f-e594-c690589ffb03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps4.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### Classification model: SamLowe/roberta-base-go_emotions"],"metadata":{"id":"1v3SnQ_dg43w"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"SamLowe/roberta-base-go_emotions\"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps5.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nyVx70oAaciD","executionInfo":{"status":"ok","timestamp":1703062188226,"user_tz":-360,"elapsed":25920,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"e5671989-1613-48d2-ca4d-474209e21b57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps5.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### classification model: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli"],"metadata":{"id":"l0fu5iCFg-B6"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps6.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAi4WqWNamXm","executionInfo":{"status":"ok","timestamp":1703062317744,"user_tz":-360,"elapsed":87174,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"bc4979a0-d3c0-4f6f-c1ea-fc1aea75515f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps6.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### Classification model:cardiffnlp/twitter-roberta-base-sentiment"],"metadata":{"id":"2FKX7DuXhDqq"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"cardiffnlp/twitter-roberta-base-sentiment\"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps7.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OBXM2KcanXi","executionInfo":{"status":"ok","timestamp":1703062358088,"user_tz":-360,"elapsed":20527,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"b4af86bb-6d73-4b51-8566-170a47cbbdd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps7.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### classification model: facebook/bart-large-mnli"],"metadata":{"id":"oV8g_lMchLp9"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"facebook/bart-large-mnli\"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps8.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnYIabI4aoUS","executionInfo":{"status":"ok","timestamp":1703062498313,"user_tz":-360,"elapsed":91117,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"a7fb50cb-fd65-402e-c55e-8aaa4ac63e01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps8.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### classification model: cardiffnlp/twitter-roberta-base-sentiment-latest"],"metadata":{"id":"OWc-2gn6hRLc"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"cardiffnlp/twitter-roberta-base-sentiment-latest\"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps9.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tb0Z9fi2tb1Z","executionInfo":{"status":"ok","timestamp":1703062608129,"user_tz":-360,"elapsed":63438,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"c2cd4e9b-7c11-4181-a2d0-7155700bb8c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps9.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### classification model: nlptown/bert-base-multilingual-uncased-sentiment"],"metadata":{"id":"tS44IqPxhWC-"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"nlptown/bert-base-multilingual-uncased-sentiment\"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps10.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6A92QpFccG5t","executionInfo":{"status":"ok","timestamp":1703062787864,"user_tz":-360,"elapsed":113758,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"7dc181f2-dc8a-4b39-c417-81b94f6d2d8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps10.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### classification model: cardiffnlp/twitter-xlm-roberta-base-sentiment"],"metadata":{"id":"gr9TFsyThbcx"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps11.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8VJSNAs_cIWT","executionInfo":{"status":"ok","timestamp":1703062908504,"user_tz":-360,"elapsed":85019,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"979584db-34b7-4dd7-ae59-9aa93478e412"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps11.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### classification model: ProsusAI/finbert"],"metadata":{"id":"g9EWW_fWhg9I"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to get the combined names for all apps associated with a model and their numbers\n","def get_combined_names_for_model(classification_model_name):\n","    base_url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    classification_combined_names = []\n","\n","    def extract_names_from_page(url):\n","        response = requests.get(url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            try:\n","                html_content = response.text\n","                soup = BeautifulSoup(html_content, 'html.parser')\n","\n","                # Find all h4 elements without specifying a class\n","                h4_elements = soup.find_all('h4')\n","\n","                # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","                a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","                # Iterate through each pair of h4 and a elements and combine the names\n","                for index, (h4_element, a_element) in enumerate(zip(h4_elements, a_elements), start=1):\n","                    app_name = h4_element.text.strip()\n","                    creator_name = a_element.text.strip()\n","                    classification_combined_name = f\"{creator_name}/{app_name}\"\n","                    classification_combined_names.append({'Model': classification_model_name, 'App Number': index, 'Combined Name': classification_combined_name})\n","\n","            except Exception as e:\n","                print(f\"Error: {e}\")\n","\n","    # Extract names from the first page\n","    extract_names_from_page(base_url)\n","\n","    # Extract names from subsequent pages\n","    page_number = 1\n","    while True:\n","        next_page_url = f\"{base_url}&p={page_number}\"\n","        response = requests.get(next_page_url)\n","        if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","            extract_names_from_page(next_page_url)\n","            page_number += 1\n","        else:\n","            break\n","\n","    return classification_combined_names\n","\n","# Example list of model names\n","classification_model_names = [\"ProsusAI/finbert\"]\n","\n","# Create a list to store model names and associated apps\n","classification_model_apps_list = []\n","\n","# Iterate through each model and get combined names for all apps\n","for classification_model_name in classification_model_names:\n","    classification_combined_names = get_combined_names_for_model(classification_model_name)\n","    if classification_combined_names:\n","        classification_model_apps_list.extend(classification_combined_names)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'classification_model_apps12.csv'\n","fieldnames = ['Model', 'App Number', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(classification_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names, app numbers, and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"biE4oHpgcJp5","executionInfo":{"status":"ok","timestamp":1703062958175,"user_tz":-360,"elapsed":27138,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"bfbe83e9-b501-431c-bb21-02949a0819a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'classification_model_apps12.csv' has been created with model names, app numbers, and combined names.\n"]}]},{"cell_type":"markdown","source":["### combining all classification models apps."],"metadata":{"id":"aQ0OT5q8hnaI"}},{"cell_type":"code","source":["import pandas as pd\n","import glob\n","\n","# Specify the path where your CSV files are located\n","csv_files_path = '/content/*.csv'\n","\n","\n","# Use glob to get a list of all CSV files in the specified path\n","csv_files = glob.glob(csv_files_path)\n","\n","# Create an empty DataFrame to store the combined data\n","combined_df = pd.DataFrame()\n","\n","# Iterate through each CSV file and concatenate the data\n","for csv_file in csv_files:\n","    df = pd.read_csv(csv_file)\n","    combined_df = pd.concat([combined_df, df], ignore_index=True)\n","\n","# Save the combined data to a new CSV file\n","combined_csv_file_path = '/content/all_classification_model_apps.csv'\n","combined_df.to_csv(combined_csv_file_path, index=False)\n","\n","print(f\"Combined CSV file '{combined_csv_file_path}' has been created.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmmbZlMzdYx3","executionInfo":{"status":"ok","timestamp":1703063033691,"user_tz":-360,"elapsed":604,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"af878636-9423-47bc-a6c8-8754d9dfa8d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Combined CSV file '/content/all_classification_model_apps.csv' has been created.\n"]}]},{"cell_type":"markdown","source":["# obtain and compare the source code size of the ML apps (\"spaces\") obtained in step 2 (HINT: check the \"Files\" tab at the top-right of a given space's page)"],"metadata":{"id":"U_1T8OCbPj9_"}},{"cell_type":"markdown","source":["## classification model apps size"],"metadata":{"id":"fR3NzsT2UYqW"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to extract size from HTML content\n","def get_size_from_html(html_content):\n","    soup = BeautifulSoup(html_content, 'html.parser')\n","    byte_sum = 0\n","    for tag in soup.find_all(text=True):\n","        if 'byte' in tag.lower():\n","            try:\n","                byte_value = int(tag.split()[0])\n","                byte_sum += byte_value\n","            except ValueError:\n","                pass\n","    return byte_sum\n","\n","# Function to fetch HTML content of a given URL\n","def get_html_content(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        return response.text\n","    else:\n","        return None\n","\n","# Read CSV file\n","csv_file_path = '/content/all_classification_model_apps.csv'  # Replace with the path to your CSV file\n","output_csv_file_path = 'classification_app_size.csv'  # New CSV file for app sizes\n","\n","with open(csv_file_path, 'r') as file, open(output_csv_file_path, 'w', newline='') as output_file:\n","    # Create CSV writer\n","    fieldnames = ['classification_Model', 'App Name', 'App Size (bytes)']\n","    writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n","\n","    # Write header to the output file\n","    writer.writeheader()\n","\n","    reader = csv.DictReader(file)\n","\n","    # Iterate through each row in the CSV\n","    for row in reader:\n","        model_name = row['Model']\n","        combined_name = row['App Name']\n","\n","        # Replace spaces with dashes\n","        formatted_combined_name = combined_name.replace(' ', '-')\n","\n","        # Generate the URL\n","        url = f'https://huggingface.co/spaces/{formatted_combined_name}/tree/main'\n","        print(url)\n","\n","        # Fetch HTML content\n","        html_content = get_html_content(url)\n","\n","        if html_content is not None:\n","            # Extract size from HTML\n","            app_size = get_size_from_html(html_content)\n","\n","            # Write to the output file\n","            writer.writerow({'classification_Model': model_name, 'App Name': combined_name, 'App Size (bytes)': app_size})\n","\n","            # Print or store the result as needed\n","            print(f'classification_Model: {model_name}, App Name : {combined_name}, App Size: {app_size} bytes')\n","        else:\n","            print(f'Error fetching content for Model: {model_name}, Combined Name: {combined_name}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qe3npcoiOPed","executionInfo":{"status":"ok","timestamp":1703064790966,"user_tz":-360,"elapsed":67641,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"936c3109-20f4-4d2d-f9ac-fe85e26b4348"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://huggingface.co/spaces/happyhaplu/MoritzLaurer-DeBERTa-V3-Base-Mnli-Fever-Anli/tree/main\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-88-76662553953b>:9: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n","  for tag in soup.find_all(text=True):\n"]},{"output_type":"stream","name":"stdout","text":["classification_Model: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli, App Name : happyhaplu/MoritzLaurer DeBERTa V3 Base Mnli Fever Anli, App Size: 367 bytes\n","https://huggingface.co/spaces/Jofthomas/MoritzLaurer-DeBERTa-V3-Base-Mnli-Fever-Anli/tree/main\n","classification_Model: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli, App Name : Jofthomas/MoritzLaurer DeBERTa V3 Base Mnli Fever Anli, App Size: 369 bytes\n","https://huggingface.co/spaces/Avatarofhemant/MoritzLaurer-DeBERTa-V3-Base-Mnli-Fever-Anli/tree/main\n","classification_Model: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli, App Name : Avatarofhemant/MoritzLaurer DeBERTa V3 Base Mnli Fever Anli, App Size: 366 bytes\n","https://huggingface.co/spaces/awacke1/ZeroShotClassifiers-Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : awacke1/ZeroShotClassifiers Facebook Bart Large Mnli, App Size: 360 bytes\n","https://huggingface.co/spaces/awacke1/Zero-Shot-Classification-Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : awacke1/Zero Shot Classification Facebook Bart Large Mnli, App Size: 362 bytes\n","https://huggingface.co/spaces/awacke1/Easy-Button-Zero-Shot-Text-Classifier-Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : awacke1/Easy Button Zero Shot Text Classifier Facebook Bart Large Mnli, App Size: 379 bytes\n","https://huggingface.co/spaces/srikotha/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : srikotha/Facebook Bart Large Mnli, App Size: 328 bytes\n","https://huggingface.co/spaces/ceckenrode/Easy-Button-Zero-Shot-Text-Classifier-Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : ceckenrode/Easy Button Zero Shot Text Classifier Facebook Bart Large Mnli, App Size: 380 bytes\n","https://huggingface.co/spaces/JSanchez79/Js-Test-Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : JSanchez79/Js Test Facebook Bart Large Mnli, App Size: 350 bytes\n","https://huggingface.co/spaces/rholtwo/Easy-Button-Zero-Shot-Text-Classifier-Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : rholtwo/Easy Button Zero Shot Text Classifier Facebook Bart Large Mnli, App Size: 467 bytes\n","https://huggingface.co/spaces/Unfaithful/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : Unfaithful/Facebook Bart Large Mnli, App Size: 326 bytes\n","https://huggingface.co/spaces/eldoraboo/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : eldoraboo/Facebook Bart Large Mnli, App Size: 341 bytes\n","https://huggingface.co/spaces/awacke1/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : awacke1/Facebook Bart Large Mnli, App Size: 340 bytes\n","https://huggingface.co/spaces/dipesh/Zeroshot-Classifire-Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : dipesh/Zeroshot Classifire Facebook Bart Large Mnli, App Size: 348 bytes\n","https://huggingface.co/spaces/1sernumVimke/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : 1sernumVimke/Facebook Bart Large Mnli, App Size: 390 bytes\n","https://huggingface.co/spaces/exiao3/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : exiao3/Facebook Bart Large Mnli, App Size: 343 bytes\n","https://huggingface.co/spaces/dennis1940/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : dennis1940/Facebook Bart Large Mnli, App Size: 324 bytes\n","https://huggingface.co/spaces/damondou/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : damondou/Facebook Bart Large Mnli, App Size: 330 bytes\n","https://huggingface.co/spaces/domnic/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : domnic/Facebook Bart Large Mnli, App Size: 324 bytes\n","https://huggingface.co/spaces/lakshaydulani/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : lakshaydulani/Facebook Bart Large Mnli, App Size: 326 bytes\n","https://huggingface.co/spaces/DavidMbx/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : DavidMbx/Facebook Bart Large Mnli, App Size: 329 bytes\n","https://huggingface.co/spaces/LucasMateru/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : LucasMateru/Facebook Bart Large Mnli, App Size: 328 bytes\n","https://huggingface.co/spaces/A-Team/Classification-Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : A-Team/Classification Facebook Bart Large Mnli, App Size: 323 bytes\n","https://huggingface.co/spaces/smitty3848/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : smitty3848/Facebook Bart Large Mnli, App Size: 343 bytes\n","https://huggingface.co/spaces/araoLeger360/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : araoLeger360/Facebook Bart Large Mnli, App Size: 337 bytes\n","https://huggingface.co/spaces/letro00/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : letro00/Facebook Bart Large Mnli, App Size: 326 bytes\n","https://huggingface.co/spaces/vkthakur88/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : vkthakur88/Facebook Bart Large Mnli, App Size: 324 bytes\n","https://huggingface.co/spaces/BillBojangeles2000/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : BillBojangeles2000/Facebook Bart Large Mnli, App Size: 342 bytes\n","https://huggingface.co/spaces/fujiwaratakumi/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : fujiwaratakumi/Facebook Bart Large Mnli, App Size: 312 bytes\n","https://huggingface.co/spaces/umm-maybe/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : umm-maybe/Facebook Bart Large Mnli, App Size: 316 bytes\n","https://huggingface.co/spaces/flashco/Facebook-Bart-Large-Mnli/tree/main\n","classification_Model: facebook/bart-large-mnli, App Name : flashco/Facebook Bart Large Mnli, App Size: 336 bytes\n","https://huggingface.co/spaces/Mavrck307/Mrm8488-Distilroberta-Finetuned-Financial-News-Sentiment-Analysis/tree/main\n","classification_Model: mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, App Name : Mavrck307/Mrm8488 Distilroberta Finetuned Financial News Sentiment Analysis, App Size: 409 bytes\n","https://huggingface.co/spaces/jboyerjr/Mrm8488-Distilroberta-Finetuned-Financial-News-Sentiment-Analysis/tree/main\n","classification_Model: mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, App Name : jboyerjr/Mrm8488 Distilroberta Finetuned Financial News Sentiment Analysis, App Size: 413 bytes\n","https://huggingface.co/spaces/Swindu/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : Swindu/ProsusAI Finbert, App Size: 310 bytes\n","https://huggingface.co/spaces/ateliershen/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : ateliershen/ProsusAI Finbert, App Size: 313 bytes\n","https://huggingface.co/spaces/huangtianba/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : huangtianba/ProsusAI Finbert, App Size: 309 bytes\n","https://huggingface.co/spaces/2gauravc/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : 2gauravc/ProsusAI Finbert, App Size: 331 bytes\n","https://huggingface.co/spaces/daramaccoille/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : daramaccoille/ProsusAI Finbert, App Size: 309 bytes\n","https://huggingface.co/spaces/asungajinli/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : asungajinli/ProsusAI Finbert, App Size: 309 bytes\n","https://huggingface.co/spaces/justlookup/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : justlookup/ProsusAI Finbert, App Size: 310 bytes\n","https://huggingface.co/spaces/alexpaul/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : alexpaul/ProsusAI Finbert, App Size: 298 bytes\n","https://huggingface.co/spaces/jdelgado2002/ProsusAI-Finbert/tree/main\n","classification_Model: ProsusAI/finbert, App Name : jdelgado2002/ProsusAI Finbert, App Size: 302 bytes\n","https://huggingface.co/spaces/joey1895/Nlptown-Bert-Base-Multilingual-Uncased-Sentiment/tree/main\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, App Name : joey1895/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 407 bytes\n","https://huggingface.co/spaces/alexanderander30/Nlptown-Bert-Base-Multilingual-Uncased-Sentiment/tree/main\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, App Name : alexanderander30/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 374 bytes\n","https://huggingface.co/spaces/Abdel/Nlptown-Bert-Base-Multilingual-Uncased-Sentiment/tree/main\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, App Name : Abdel/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 373 bytes\n","https://huggingface.co/spaces/Sowmya1022/Nlptown-Bert-Base-Multilingual-Uncased-Sentiment/tree/main\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, App Name : Sowmya1022/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 376 bytes\n","https://huggingface.co/spaces/ans123/Nlptown-Bert-Base-Multilingual-Uncased-Sentiment/tree/main\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, App Name : ans123/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 374 bytes\n","https://huggingface.co/spaces/msalazark/Cardiffnlp-Twitter-Xlm-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-xlm-roberta-base-sentiment, App Name : msalazark/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 370 bytes\n","https://huggingface.co/spaces/zox47/Cardiffnlp-Twitter-Xlm-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-xlm-roberta-base-sentiment, App Name : zox47/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 367 bytes\n","https://huggingface.co/spaces/psycen/Cardiffnlp-Twitter-Xlm-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-xlm-roberta-base-sentiment, App Name : psycen/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 366 bytes\n","https://huggingface.co/spaces/834188divi/Cardiffnlp-Twitter-Xlm-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-xlm-roberta-base-sentiment, App Name : 834188divi/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 371 bytes\n","https://huggingface.co/spaces/834188divi/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : 834188divi/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/FrancescoBerg/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : FrancescoBerg/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/dajayk12/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : dajayk12/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","https://huggingface.co/spaces/Daniton/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : Daniton/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/Daniton/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : Daniton/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/quni/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : quni/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 390 bytes\n","https://huggingface.co/spaces/alpha-hp/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : alpha-hp/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 376 bytes\n","https://huggingface.co/spaces/bobrooos/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : bobrooos/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/zox47/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : zox47/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","https://huggingface.co/spaces/TestSpace/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : TestSpace/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 378 bytes\n","https://huggingface.co/spaces/TestSpace/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest-Gradio/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : TestSpace/Cardiffnlp Twitter Roberta Base Sentiment Latest Gradio, App Size: 381 bytes\n","https://huggingface.co/spaces/salmanmoh/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : salmanmoh/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 391 bytes\n","https://huggingface.co/spaces/10isha/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : 10isha/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 372 bytes\n","https://huggingface.co/spaces/sotirios-slv/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : sotirios-slv/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","https://huggingface.co/spaces/Fatima33/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : Fatima33/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/data2science/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : data2science/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/wsaults/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : wsaults/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 393 bytes\n","https://huggingface.co/spaces/dx1/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : dx1/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 372 bytes\n","https://huggingface.co/spaces/farooq-09/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, App Name : farooq-09/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 393 bytes\n","https://huggingface.co/spaces/Vadala/SamLowe-roberta-base-go_emotions/tree/main\n","classification_Model: SamLowe/roberta-base-go_emotions, App Name : Vadala/SamLowe-roberta-base-go_emotions, App Size: 332 bytes\n","https://huggingface.co/spaces/feierdun/SamLowe-roberta-base-go_emotions/tree/main\n","classification_Model: SamLowe/roberta-base-go_emotions, App Name : feierdun/SamLowe-roberta-base-go_emotions, App Size: 361 bytes\n","https://huggingface.co/spaces/detian/SamLowe-roberta-base-go_emotions/tree/main\n","classification_Model: SamLowe/roberta-base-go_emotions, App Name : detian/SamLowe-roberta-base-go_emotions, App Size: 341 bytes\n","https://huggingface.co/spaces/TIXTPCOA/SamLowe-roberta-base-go_emotions/tree/main\n","classification_Model: SamLowe/roberta-base-go_emotions, App Name : TIXTPCOA/SamLowe-roberta-base-go_emotions, App Size: 341 bytes\n","https://huggingface.co/spaces/agkbv/SamLowe-roberta-base-go_emotions/tree/main\n","classification_Model: SamLowe/roberta-base-go_emotions, App Name : agkbv/SamLowe-roberta-base-go_emotions, App Size: 362 bytes\n","https://huggingface.co/spaces/kaungmyat/SamLowe-roberta-base-go_emotions/tree/main\n","classification_Model: SamLowe/roberta-base-go_emotions, App Name : kaungmyat/SamLowe-roberta-base-go_emotions, App Size: 343 bytes\n","https://huggingface.co/spaces/Maryam-1/SamLowe-roberta-base-go_emotions/tree/main\n","classification_Model: SamLowe/roberta-base-go_emotions, App Name : Maryam-1/SamLowe-roberta-base-go_emotions, App Size: 345 bytes\n","https://huggingface.co/spaces/testDS/SamLowe-roberta-base-go_emotions/tree/main\n","classification_Model: SamLowe/roberta-base-go_emotions, App Name : testDS/SamLowe-roberta-base-go_emotions, App Size: 351 bytes\n","https://huggingface.co/spaces/834188divi/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : 834188divi/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/FrancescoBerg/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : FrancescoBerg/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/dajayk12/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : dajayk12/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","https://huggingface.co/spaces/Daniton/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : Daniton/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/Daniton/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : Daniton/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/quni/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : quni/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 390 bytes\n","https://huggingface.co/spaces/msalazark/Cardiffnlp-Twitter-Xlm-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : msalazark/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 370 bytes\n","https://huggingface.co/spaces/alpha-hp/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : alpha-hp/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 376 bytes\n","https://huggingface.co/spaces/xingxing12/Cardiffnlp-Twitter-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : xingxing12/Cardiffnlp Twitter Roberta Base Sentiment, App Size: 378 bytes\n","https://huggingface.co/spaces/bobrooos/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : bobrooos/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/zox47/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : zox47/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","https://huggingface.co/spaces/zox47/Cardiffnlp-Twitter-Xlm-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : zox47/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 367 bytes\n","https://huggingface.co/spaces/psycen/Cardiffnlp-Twitter-Xlm-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : psycen/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 366 bytes\n","https://huggingface.co/spaces/834188divi/Cardiffnlp-Twitter-Xlm-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : 834188divi/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 371 bytes\n","https://huggingface.co/spaces/asungajinli/Cardiffnlp-Twitter-Roberta-Base-Sentiment/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : asungajinli/Cardiffnlp Twitter Roberta Base Sentiment, App Size: 363 bytes\n","https://huggingface.co/spaces/TestSpace/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : TestSpace/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 378 bytes\n","https://huggingface.co/spaces/TestSpace/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest-Gradio/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : TestSpace/Cardiffnlp Twitter Roberta Base Sentiment Latest Gradio, App Size: 381 bytes\n","https://huggingface.co/spaces/salmanmoh/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : salmanmoh/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 391 bytes\n","https://huggingface.co/spaces/10isha/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : 10isha/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 372 bytes\n","https://huggingface.co/spaces/sotirios-slv/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : sotirios-slv/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","https://huggingface.co/spaces/Fatima33/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : Fatima33/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/data2science/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : data2science/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","https://huggingface.co/spaces/wsaults/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : wsaults/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 393 bytes\n","https://huggingface.co/spaces/dx1/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : dx1/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 372 bytes\n","https://huggingface.co/spaces/farooq-09/Cardiffnlp-Twitter-Roberta-Base-Sentiment-Latest/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, App Name : farooq-09/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 393 bytes\n","https://huggingface.co/spaces/Norod78/distilgpt2_TextIteratorStreamer/tree/main\n","classification_Model: distilgpt2, App Name : Norod78/distilgpt2_TextIteratorStreamer, App Size: 304 bytes\n","https://huggingface.co/spaces/ICML2022/Distilgpt2-Finetuned-Wikitext103/tree/main\n","classification_Model: distilgpt2, App Name : ICML2022/Distilgpt2 Finetuned Wikitext103, App Size: 355 bytes\n","https://huggingface.co/spaces/tj5miniop/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : tj5miniop/Distilgpt2, App Size: 329 bytes\n","https://huggingface.co/spaces/pp3232133/Pp3232133-Distilgpt2-Wikitext2/tree/main\n","classification_Model: distilgpt2, App Name : pp3232133/Pp3232133 Distilgpt2 Wikitext2, App Size: 419 bytes\n","https://huggingface.co/spaces/canonsky1992/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : canonsky1992/Distilgpt2, App Size: 882 bytes\n","https://huggingface.co/spaces/Norod78/distilgpt2-harrypotter-he/tree/main\n","classification_Model: distilgpt2, App Name : Norod78/distilgpt2-harrypotter-he, App Size: 346 bytes\n","https://huggingface.co/spaces/Wizardman381/FredZhang7-Distilgpt2-Stable-Diffusion-V2/tree/main\n","classification_Model: distilgpt2, App Name : Wizardman381/FredZhang7 Distilgpt2 Stable Diffusion V2, App Size: 361 bytes\n","https://huggingface.co/spaces/BearDadBod/FredZhang7-Distilgpt2-Stable-Diffusion-V2/tree/main\n","classification_Model: distilgpt2, App Name : BearDadBod/FredZhang7 Distilgpt2 Stable Diffusion V2, App Size: 363 bytes\n","https://huggingface.co/spaces/zjb/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : zjb/Distilgpt2, App Size: 315 bytes\n","https://huggingface.co/spaces/Dao3/FredZhang7-Distilgpt2-Stable-Diffusion-V2/tree/main\n","classification_Model: distilgpt2, App Name : Dao3/FredZhang7 Distilgpt2 Stable Diffusion V2, App Size: 362 bytes\n","https://huggingface.co/spaces/bear222/Shibing624-Code-Autocomplete-Distilgpt2-Python/tree/main\n","classification_Model: distilgpt2, App Name : bear222/Shibing624 Code Autocomplete Distilgpt2 Python, App Size: 392 bytes\n","https://huggingface.co/spaces/habby223/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : habby223/Distilgpt2, App Size: 347 bytes\n","https://huggingface.co/spaces/Tomas1234566/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : Tomas1234566/Distilgpt2, App Size: 299 bytes\n","https://huggingface.co/spaces/njmery/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : njmery/Distilgpt2, App Size: 297 bytes\n","https://huggingface.co/spaces/zhongdj/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : zhongdj/Distilgpt2, App Size: 297 bytes\n","https://huggingface.co/spaces/TheBitterLemon/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : TheBitterLemon/Distilgpt2, App Size: 298 bytes\n","https://huggingface.co/spaces/acalVriatsu/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : acalVriatsu/Distilgpt2, App Size: 0 bytes\n","https://huggingface.co/spaces/Decryptu/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : Decryptu/Distilgpt2, App Size: 298 bytes\n","https://huggingface.co/spaces/TalZaccai/TalZaccai-distilgpt2_friends/tree/main\n","classification_Model: distilgpt2, App Name : TalZaccai/TalZaccai-distilgpt2_friends, App Size: 289 bytes\n","https://huggingface.co/spaces/dennywu2966/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : dennywu2966/Distilgpt2, App Size: 298 bytes\n","https://huggingface.co/spaces/anmoll/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : anmoll/Distilgpt2, App Size: 299 bytes\n","https://huggingface.co/spaces/sidmanale643/DunnBC22-distilgpt2-2k_clean_medical_articles_causal_language_model/tree/main\n","classification_Model: distilgpt2, App Name : sidmanale643/DunnBC22-distilgpt2-2k_clean_medical_articles_causal_language_model, App Size: 413 bytes\n","https://huggingface.co/spaces/Amal17/Distilgpt2-Acewiki/tree/main\n","classification_Model: distilgpt2, App Name : Amal17/Distilgpt2 Acewiki, App Size: 1189 bytes\n","https://huggingface.co/spaces/mamechapa2/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : mamechapa2/Distilgpt2, App Size: 296 bytes\n","https://huggingface.co/spaces/JunRyeol/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : JunRyeol/Distilgpt2, App Size: 299 bytes\n","https://huggingface.co/spaces/dsank/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : dsank/Distilgpt2, App Size: 296 bytes\n","https://huggingface.co/spaces/Eduard2806/New12/tree/main\n","classification_Model: distilgpt2, App Name : Eduard2806/New12, App Size: 473 bytes\n","https://huggingface.co/spaces/en2ie/Distilgpt2/tree/main\n","classification_Model: distilgpt2, App Name : en2ie/Distilgpt2, App Size: 287 bytes\n","https://huggingface.co/spaces/DogManTC/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : DogManTC/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 1291 bytes\n","https://huggingface.co/spaces/cmorato/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : cmorato/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 370 bytes\n","https://huggingface.co/spaces/rcuchoa/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : rcuchoa/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 393 bytes\n","https://huggingface.co/spaces/leolinardi/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : leolinardi/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 373 bytes\n","https://huggingface.co/spaces/Offdutyninja/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : Offdutyninja/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 373 bytes\n","https://huggingface.co/spaces/Jayod/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : Jayod/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 375 bytes\n","https://huggingface.co/spaces/RaoMuneeb/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : RaoMuneeb/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 372 bytes\n","https://huggingface.co/spaces/glrh11/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : glrh11/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 716 bytes\n","https://huggingface.co/spaces/wesley7137/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : wesley7137/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 373 bytes\n","https://huggingface.co/spaces/asapjabber/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : asapjabber/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 375 bytes\n","https://huggingface.co/spaces/ozxdisma/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : ozxdisma/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 410 bytes\n","https://huggingface.co/spaces/mahaanand/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : mahaanand/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 377 bytes\n","https://huggingface.co/spaces/kaungmyat/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : kaungmyat/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 371 bytes\n","https://huggingface.co/spaces/alexpaul/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : alexpaul/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 372 bytes\n","https://huggingface.co/spaces/alanbabygirl/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : alanbabygirl/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 362 bytes\n","https://huggingface.co/spaces/z0mz0m/Distilbert-Base-Uncased-Finetuned-Sst-2-English/tree/main\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, App Name : z0mz0m/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 372 bytes\n","https://huggingface.co/spaces/Eberhenriquez/Cardiffnlp-Twitter-Roberta-Base-Irony/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-irony, App Name : Eberhenriquez/Cardiffnlp Twitter Roberta Base Irony, App Size: 371 bytes\n","https://huggingface.co/spaces/interestedperson/Cardiffnlp-Twitter-Roberta-Base-Irony/tree/main\n","classification_Model: cardiffnlp/twitter-roberta-base-irony, App Name : interestedperson/Cardiffnlp Twitter Roberta Base Irony, App Size: 342 bytes\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load data\n","df = pd.read_csv('/content/classification_app_size.csv')\n","app_size_stats = df['App Size (bytes)'].describe()\n","print(app_size_stats)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e93KdfrY9xbO","executionInfo":{"status":"ok","timestamp":1703088226126,"user_tz":-360,"elapsed":8,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"0c6b3641-7809-411e-d5ab-1a3c29673077"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["count     149.000000\n","mean      372.409396\n","std       122.584555\n","min         0.000000\n","25%       331.000000\n","50%       370.000000\n","75%       375.000000\n","max      1291.000000\n","Name: App Size (bytes), dtype: float64\n"]}]}]}