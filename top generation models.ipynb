{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"134We1_l8r_3FnNr7XpDrY1jhXOAEITla","timestamp":1702982465400}],"machine_shape":"hm","authorship_tag":"ABX9TyNMNYdyHLyUS7VUXSd1VM7D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPZI61vCKf0Z","executionInfo":{"status":"ok","timestamp":1702978657451,"user_tz":-360,"elapsed":6333,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"d0cb8e06-2ca2-4c6a-a282-dde00973fb48"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","source":["# obtain a list of the top-20 \"Text Classification\" and top-20 \"Text Generation\" models on https://huggingface.co/, ranked based on popularity"],"metadata":{"id":"-2I8u_avPKTx"}},{"cell_type":"code","source":["import csv\n","from huggingface_hub import HfApi\n","\n","# Function to get all models with a specific tag\n","def get_models_by_tag(tag):\n","    hf_api = HfApi(endpoint=\"https://huggingface.co\")\n","    all_models = hf_api.list_models()\n","    tag_models = [model for model in all_models if tag.lower() in [model_tag.lower() for model_tag in model.tags]]\n","    return tag_models\n","\n","# Get all \"text classification\" models\n","text_generation_models = get_models_by_tag(\"text-generation\")\n","\n","# Sort models by downloads in descending order\n","text_generation_models_sorted = sorted(text_generation_models, key=lambda x: x.downloads, reverse=True)\n","\n","# Prepare data for CSV\n","csv_data = [[\"Rank\", \"Model ID\", \"Downloads\"]]\n","for i, model in enumerate(text_generation_models_sorted[:20]):\n","    csv_data.append([i + 1, model.modelId, model.downloads])\n","\n","# Save to CSV file\n","csv_file_path = \"top_text_generation_models.csv\"\n","with open(csv_file_path, mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(csv_data)"],"metadata":{"id":"LfbIY2Dyl-FP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now model_names contains the names of the first 10 text classification models\n","print(\"Model names array:\", text_generation_model_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fnaZfONgDFK","executionInfo":{"status":"ok","timestamp":1702978753243,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"5426e96f-d07d-4810-99ae-16e17ca379ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model names array: ['distilgpt2', 'gpt2', 'davidkim205/komt-mistral-7b-v1', 'tiiuae/falcon-40b-instruct', 'bigscience/bloom-560m', 'meta-llama/Llama-2-7b-chat-hf', 'petals-team/StableBeluga2', 'facebook/opt-1.3b', 'HuggingFaceM4/tiny-random-LlamaForCausalLM', 'TheBloke/CodeLlama-34B-Instruct-GPTQ', 'facebook/opt-125m', 'microsoft/git-base', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mistral-7B-v0.1', 'meta-llama/Llama-2-7b-hf', 'TheBloke/Llama-2-7B-Chat-GPTQ', 'gpt2-medium', 'gpt2-large', 'NousResearch/Nous-Hermes-Llama2-13b', 'ehartford/Samantha-1.11-70b']\n"]}]},{"cell_type":"markdown","source":[" # obtain and compare the number of ML apps (\"spaces\") for each \"Text Classification\" and \"Text Generation\" model obtained in step 1"],"metadata":{"id":"xIuMe15iPekQ"}},{"cell_type":"code","source":["!pip install requests\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"np8bVzSawcN1","executionInfo":{"status":"ok","timestamp":1702978759192,"user_tz":-360,"elapsed":5953,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"e2142b57-9e39-4d3e-9654-a0f588f88f5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n"]}]},{"cell_type":"code","source":["!pip install requests beautifulsoup4\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1FoacxtWG-F","executionInfo":{"status":"ok","timestamp":1702978765004,"user_tz":-360,"elapsed":5818,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"34c4875b-9af9-4053-8d18-52701ed078cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"eK4KP194Ps2N"}},{"cell_type":"markdown","source":["## obtain and compare the number of ML apps (\"spaces\") for each \"Text Classification\""],"metadata":{"id":"whNCB1v_PwvA"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","from huggingface_hub import HfApi\n","\n","# Function to get the number of articles for a model\n","def get_num_articles(classification_model_name):\n","    url = f\"https://huggingface.co/spaces?sort=likes&search={classification_model_name}\"\n","    response = requests.get(url)\n","\n","    if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","        try:\n","            html_content = response.text\n","            soup = BeautifulSoup(html_content, 'html.parser')\n","\n","            # Find the div with class \"grid grid-cols-1 gap-x-4 gap-y-6 md:grid-cols-3 xl:grid-cols-4\"\n","            class_div = soup.find('div', class_='grid grid-cols-1 gap-x-4 gap-y-6 md:grid-cols-3 xl:grid-cols-4')\n","\n","            if class_div:\n","                # Find all articles under the div\n","                articles = class_div.find_all('article', class_='')\n","\n","                # Return the number of articles\n","                return len(articles)\n","            else:\n","                return 0\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            return 0\n","    else:\n","        print(f\"Error: {response.status_code} - {response.text}\")\n","        return 0\n","\n","# Function to get all models with a specific tag\n","def get_models_by_tag(tag):\n","    hf_api = HfApi(endpoint=\"https://huggingface.co\")\n","    all_models = hf_api.list_models()\n","    tag_models = [model for model in all_models if tag.lower() in [model_tag.lower() for model_tag in model.tags]]\n","    return tag_models\n","\n","# Get all \"text classification\" models\n","text_classification_models = get_models_by_tag(\"text-classification\")\n","\n","# Sort models by downloads in descending order\n","text_classification_models_sorted = sorted(text_classification_models, key=lambda x: x.downloads, reverse=True)\n","\n","# Save model names in an array\n","classification_model_names = []\n","\n","# Display information about \"text classification\" models and get the number of articles for each model\n","for i, model in enumerate(text_classification_models_sorted[:20]):\n","    classification_model_names.append(model.modelId)\n","    modified_url = f\"https://huggingface.co/spaces?sort=likes&search={model.modelId}\"\n","\n","    # Fetch the number of articles for the current model\n","    num_articles = get_num_articles(model.modelId)\n","\n","    print(f\"{i+1}. {model.modelId} - Downloads: {model.downloads}\")\n","    print(f\"   Tags: {', '.join(model.tags)}\")\n","    print(f\"   Last Modified: {model.lastModified}\")\n","    print(f\"   Number of apps: {num_articles}\\n\")\n","\n","# Now model_names contains the names of the first 10 text classification models\n","print(\"Model names array:\", classification_model_names)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_S7wVVPGhu_t","executionInfo":{"status":"ok","timestamp":1702978824333,"user_tz":-360,"elapsed":59333,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"4e634c01-2695-4929-cd72-c34249a06709"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. distilbert-base-uncased-finetuned-sst-2-english - Downloads: 8612633\n","   Tags: transformers, pytorch, tf, rust, onnx, safetensors, distilbert, text-classification, en, dataset:sst2, dataset:glue, arxiv:1910.01108, doi:10.57967/hf/0181, license:apache-2.0, model-index, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 16\n","\n","2. cardiffnlp/twitter-roberta-base-irony - Downloads: 7199260\n","   Tags: transformers, pytorch, tf, jax, roberta, text-classification, en, dataset:tweet_eval, arxiv:2010.12421, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 2\n","\n","3. lxyuan/distilbert-base-multilingual-cased-sentiments-student - Downloads: 7116579\n","   Tags: transformers, pytorch, safetensors, distilbert, text-classification, sentiment-analysis, zero-shot-distillation, distillation, zero-shot-classification, debarta-v3, en, ar, de, es, fr, ja, zh, id, hi, it, ms, pt, dataset:tyqiangz/multilingual-sentiments, doi:10.57967/hf/1422, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","4. mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis - Downloads: 6753803\n","   Tags: transformers, pytorch, tensorboard, safetensors, roberta, text-classification, generated_from_trainer, financial, stocks, sentiment, dataset:financial_phrasebank, license:apache-2.0, model-index, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 2\n","\n","5. SamLowe/roberta-base-go_emotions - Downloads: 6689743\n","   Tags: transformers, pytorch, safetensors, roberta, text-classification, emotions, multi-class-classification, multi-label-classification, en, dataset:go_emotions, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 8\n","\n","6. marieke93/MiniLM-evidence-types - Downloads: 6623956\n","   Tags: transformers, pytorch, tensorboard, bert, text-classification, generated_from_trainer, license:mit, autotrain_compatible, endpoints_compatible, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","7. Ashishkr/query_wellformedness_score - Downloads: 6623448\n","   Tags: transformers, pytorch, jax, safetensors, roberta, text-classification, dataset:google_wellformed_query, license:apache-2.0, autotrain_compatible, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","8. MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli - Downloads: 5662428\n","   Tags: transformers, pytorch, safetensors, deberta-v2, text-classification, zero-shot-classification, en, dataset:multi_nli, dataset:anli, dataset:fever, arxiv:2006.03654, license:mit, model-index, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 3\n","\n","9. cardiffnlp/twitter-roberta-base-sentiment - Downloads: 3838928\n","   Tags: transformers, pytorch, tf, jax, roberta, text-classification, en, dataset:tweet_eval, arxiv:2010.12421, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","10. facebook/bart-large-mnli - Downloads: 2478111\n","   Tags: transformers, pytorch, jax, rust, safetensors, bart, text-classification, zero-shot-classification, dataset:multi_nli, arxiv:1910.13461, arxiv:1909.00161, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","11. cardiffnlp/twitter-roberta-base-sentiment-latest - Downloads: 2180511\n","   Tags: transformers, pytorch, tf, roberta, text-classification, en, dataset:tweet_eval, arxiv:2202.03829, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 19\n","\n","12. nlptown/bert-base-multilingual-uncased-sentiment - Downloads: 1637102\n","   Tags: transformers, pytorch, tf, jax, bert, text-classification, en, nl, de, fr, it, es, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 5\n","\n","13. cardiffnlp/twitter-xlm-roberta-base-sentiment - Downloads: 1448149\n","   Tags: transformers, pytorch, tf, xlm-roberta, text-classification, multilingual, arxiv:2104.12250, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 4\n","\n","14. papluca/xlm-roberta-base-language-detection - Downloads: 1144449\n","   Tags: transformers, pytorch, tf, xlm-roberta, text-classification, generated_from_trainer, multilingual, ar, bg, de, el, en, es, fr, hi, it, ja, nl, pl, pt, ru, sw, th, tr, ur, vi, zh, arxiv:1911.02116, base_model:xlm-roberta-base, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","15. ProsusAI/finbert - Downloads: 920528\n","   Tags: transformers, pytorch, tf, jax, bert, text-classification, financial-sentiment-analysis, sentiment-analysis, en, arxiv:1908.10063, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 9\n","\n","16. cross-encoder/ms-marco-TinyBERT-L-2-v2 - Downloads: 896577\n","   Tags: transformers, pytorch, jax, bert, text-classification, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","17. cross-encoder/ms-marco-MiniLM-L-4-v2 - Downloads: 879734\n","   Tags: transformers, pytorch, jax, bert, text-classification, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","18. martin-ha/toxic-comment-model - Downloads: 852801\n","   Tags: transformers, pytorch, distilbert, text-classification, en, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","19. alexandrainst/scandi-nli-large - Downloads: 741649\n","   Tags: transformers, pytorch, safetensors, bert, text-classification, zero-shot-classification, da, no, nb, sv, dataset:strombergnlp/danfever, dataset:KBLab/overlim, dataset:MoritzLaurer/multilingual-NLI-26lang-2mil7, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","20. laiyer/deberta-v3-base-prompt-injection - Downloads: 679058\n","   Tags: transformers, onnx, safetensors, deberta-v2, text-classification, prompt-injection, injection, security, generated_from_trainer, en, dataset:Lakera/gandalf_ignore_instructions, dataset:rubend18/ChatGPT-Jailbreak-Prompts, dataset:imoxto/prompt_injection_cleaned_dataset-v2, dataset:hackaprompt/hackaprompt-dataset, dataset:fka/awesome-chatgpt-prompts, dataset:teven/prompted_examples, dataset:Dahoas/synthetic-hh-rlhf-prompts, dataset:Dahoas/hh_prompt_format, dataset:MohamedRashad/ChatGPT-prompts, dataset:HuggingFaceH4/instruction-dataset, dataset:HuggingFaceH4/no_robots, dataset:HuggingFaceH4/ultrachat_200k, base_model:microsoft/deberta-v3-base, license:apache-2.0, co2_eq_emissions, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","Model names array: ['distilbert-base-uncased-finetuned-sst-2-english', 'cardiffnlp/twitter-roberta-base-irony', 'lxyuan/distilbert-base-multilingual-cased-sentiments-student', 'mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis', 'SamLowe/roberta-base-go_emotions', 'marieke93/MiniLM-evidence-types', 'Ashishkr/query_wellformedness_score', 'MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli', 'cardiffnlp/twitter-roberta-base-sentiment', 'facebook/bart-large-mnli', 'cardiffnlp/twitter-roberta-base-sentiment-latest', 'nlptown/bert-base-multilingual-uncased-sentiment', 'cardiffnlp/twitter-xlm-roberta-base-sentiment', 'papluca/xlm-roberta-base-language-detection', 'ProsusAI/finbert', 'cross-encoder/ms-marco-TinyBERT-L-2-v2', 'cross-encoder/ms-marco-MiniLM-L-4-v2', 'martin-ha/toxic-comment-model', 'alexandrainst/scandi-nli-large', 'laiyer/deberta-v3-base-prompt-injection']\n"]}]},{"cell_type":"markdown","source":["## obtain and compare the number of ML apps (\"spaces\") for each \"Text Generation\""],"metadata":{"id":"Ne0lkmkEP08f"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","from huggingface_hub import HfApi\n","\n","# Function to get the number of articles for a model\n","def get_num_articles(generative_model_name):\n","    url = f\"https://huggingface.co/spaces?sort=likes&search={generative_model_name}\"\n","    response = requests.get(url)\n","\n","    if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","        try:\n","            html_content = response.text\n","            soup = BeautifulSoup(html_content, 'html.parser')\n","\n","            # Find the div with class \"grid grid-cols-1 gap-x-4 gap-y-6 md:grid-cols-3 xl:grid-cols-4\"\n","            class_div = soup.find('div', class_='grid grid-cols-1 gap-x-4 gap-y-6 md:grid-cols-3 xl:grid-cols-4')\n","\n","            if class_div:\n","                # Find all articles under the div\n","                articles = class_div.find_all('article', class_='')\n","\n","                # Return the number of articles\n","                return len(articles)\n","            else:\n","                return 0\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            return 0\n","    else:\n","        print(f\"Error: {response.status_code} - {response.text}\")\n","        return 0\n","\n","# Function to get all models with a specific tag\n","def get_models_by_tag(tag):\n","    hf_api = HfApi(endpoint=\"https://huggingface.co\")\n","    all_models = hf_api.list_models()\n","    tag_models = [model for model in all_models if tag.lower() in [model_tag.lower() for model_tag in model.tags]]\n","    return tag_models\n","\n","# Get all \"text generation\" models\n","text_generation_models = get_models_by_tag(\"text-generation\")\n","\n","# Sort models by downloads in descending order\n","text_generation_models_sorted = sorted(text_generation_models, key=lambda x: x.downloads, reverse=True)\n","\n","# Save model names in an array\n","generative_model_names = []\n","\n","# Display information about \"text generation\" models and get the number of articles for each model\n","for i, model in enumerate(text_generation_models_sorted[:20]):\n","    generative_model_names.append(model.modelId)\n","    modified_url = f\"https://huggingface.co/spaces?sort=likes&search={model.modelId}\"\n","\n","    # Fetch the number of articles for the current model\n","    num_articles = get_num_articles(model.modelId)\n","\n","    print(f\"{i+1}. {model.modelId} - Downloads: {model.downloads}\")\n","    print(f\"   Tags: {', '.join(model.tags)}\")\n","    print(f\"   Last Modified: {model.lastModified}\")\n","    print(f\"   Number of apps: {num_articles}\\n\")\n","\n","# Now model_names contains the names of the first 10 text generation models\n","print(\"Model names array:\", generative_model_names)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JcxH9UO-P1ly","executionInfo":{"status":"ok","timestamp":1702978880986,"user_tz":-360,"elapsed":56657,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"d8a04ef8-8e5c-4b05-ba7f-09461a992b5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. distilgpt2 - Downloads: 33709069\n","   Tags: transformers, pytorch, tf, jax, tflite, rust, coreml, safetensors, gpt2, text-generation, exbert, en, dataset:openwebtext, arxiv:1910.01108, arxiv:2201.08542, arxiv:2203.12574, arxiv:1910.09700, arxiv:1503.02531, license:apache-2.0, model-index, co2_eq_emissions, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","2. gpt2 - Downloads: 16197257\n","   Tags: transformers, pytorch, tf, jax, tflite, rust, onnx, safetensors, gpt2, text-generation, exbert, en, doi:10.57967/hf/0039, license:mit, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","3. davidkim205/komt-mistral-7b-v1 - Downloads: 2913985\n","   Tags: transformers, pytorch, mistral, text-generation, finetuned, en, ko, arxiv:2308.06502, arxiv:2308.06259, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 1\n","\n","4. tiiuae/falcon-40b-instruct - Downloads: 1312079\n","   Tags: transformers, pytorch, falcon, text-generation, custom_code, en, dataset:tiiuae/falcon-refinedweb, arxiv:2205.14135, arxiv:1911.02150, arxiv:2005.14165, arxiv:2104.09864, arxiv:2306.01116, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","5. bigscience/bloom-560m - Downloads: 1181902\n","   Tags: transformers, pytorch, jax, onnx, safetensors, bloom, text-generation, ak, ar, as, bm, bn, ca, code, en, es, eu, fon, fr, gu, hi, id, ig, ki, kn, lg, ln, ml, mr, ne, nso, ny, or, pa, pt, rn, rw, sn, st, sw, ta, te, tn, ts, tum, tw, ur, vi, wo, xh, yo, zh, zhs, zht, zu, arxiv:1909.08053, arxiv:2110.02861, arxiv:2108.12409, license:bigscience-bloom-rail-1.0, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 20\n","\n","6. meta-llama/Llama-2-7b-chat-hf - Downloads: 762371\n","   Tags: transformers, pytorch, safetensors, llama, text-generation, facebook, meta, llama-2, en, arxiv:2307.09288, autotrain_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","7. petals-team/StableBeluga2 - Downloads: 740555\n","   Tags: transformers, safetensors, llama, text-generation, en, dataset:conceptofmind/cot_submix_original, dataset:conceptofmind/flan2021_submix_original, dataset:conceptofmind/t0_submix_original, dataset:conceptofmind/niv2_submix_original, arxiv:2307.09288, arxiv:2306.02707, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 1\n","\n","8. facebook/opt-1.3b - Downloads: 708895\n","   Tags: transformers, pytorch, tf, jax, opt, text-generation, en, arxiv:2205.01068, arxiv:2005.14165, license:other, autotrain_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","9. HuggingFaceM4/tiny-random-LlamaForCausalLM - Downloads: 546406\n","   Tags: transformers, pytorch, llama, text-generation, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","10. TheBloke/CodeLlama-34B-Instruct-GPTQ - Downloads: 535048\n","   Tags: transformers, safetensors, llama, text-generation, llama-2, custom_code, code, arxiv:2308.12950, base_model:codellama/CodeLlama-34b-instruct-hf, license:llama2, autotrain_compatible, text-generation-inference, 4-bit, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","11. facebook/opt-125m - Downloads: 523035\n","   Tags: transformers, pytorch, tf, jax, opt, text-generation, en, arxiv:2205.01068, arxiv:2005.14165, license:other, autotrain_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 0\n","\n","12. microsoft/git-base - Downloads: 513587\n","   Tags: transformers, pytorch, safetensors, git, text-generation, vision, image-to-text, image-captioning, en, arxiv:2205.14100, license:mit, autotrain_compatible, endpoints_compatible, has_space, region:us\n","   Last Modified: None\n","   Number of apps: 5\n","\n","13. mistralai/Mistral-7B-Instruct-v0.1 - Downloads: 496173\n","   Tags: transformers, pytorch, safetensors, mistral, text-generation, finetuned, arxiv:2310.06825, license:apache-2.0, autotrain_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","14. mistralai/Mistral-7B-v0.1 - Downloads: 477537\n","   Tags: transformers, pytorch, safetensors, mistral, text-generation, pretrained, en, arxiv:2310.06825, license:apache-2.0, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","15. meta-llama/Llama-2-7b-hf - Downloads: 464416\n","   Tags: transformers, pytorch, safetensors, llama, text-generation, facebook, meta, llama-2, en, arxiv:2307.09288, autotrain_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 24\n","\n","16. TheBloke/Llama-2-7B-Chat-GPTQ - Downloads: 418055\n","   Tags: transformers, safetensors, llama, text-generation, facebook, meta, pytorch, llama-2, en, arxiv:2307.09288, base_model:meta-llama/Llama-2-7b-chat-hf, license:llama2, autotrain_compatible, text-generation-inference, 4-bit, region:us, has_space\n","   Last Modified: None\n","   Number of apps: 1\n","\n","17. gpt2-medium - Downloads: 387784\n","   Tags: transformers, pytorch, tf, jax, rust, onnx, safetensors, gpt2, text-generation, en, arxiv:1910.09700, license:mit, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 9\n","\n","18. gpt2-large - Downloads: 375170\n","   Tags: transformers, pytorch, tf, jax, rust, onnx, safetensors, gpt2, text-generation, en, arxiv:1910.09700, license:mit, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 22\n","\n","19. NousResearch/Nous-Hermes-Llama2-13b - Downloads: 345461\n","   Tags: transformers, pytorch, llama, text-generation, llama-2, self-instruct, distillation, synthetic instruction, en, license:mit, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 8\n","\n","20. ehartford/Samantha-1.11-70b - Downloads: 341468\n","   Tags: transformers, pytorch, llama, text-generation, en, dataset:ehartford/samantha-data, arxiv:2305.14314, arxiv:2205.14135, license:llama2, autotrain_compatible, endpoints_compatible, has_space, text-generation-inference, region:us\n","   Last Modified: None\n","   Number of apps: 3\n","\n","Model names array: ['distilgpt2', 'gpt2', 'davidkim205/komt-mistral-7b-v1', 'tiiuae/falcon-40b-instruct', 'bigscience/bloom-560m', 'meta-llama/Llama-2-7b-chat-hf', 'petals-team/StableBeluga2', 'facebook/opt-1.3b', 'HuggingFaceM4/tiny-random-LlamaForCausalLM', 'TheBloke/CodeLlama-34B-Instruct-GPTQ', 'facebook/opt-125m', 'microsoft/git-base', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mistral-7B-v0.1', 'meta-llama/Llama-2-7b-hf', 'TheBloke/Llama-2-7B-Chat-GPTQ', 'gpt2-medium', 'gpt2-large', 'NousResearch/Nous-Hermes-Llama2-13b', 'ehartford/Samantha-1.11-70b']\n"]}]},{"cell_type":"code","source":["generative_model_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZe_VxXDXIrI","executionInfo":{"status":"ok","timestamp":1702978880986,"user_tz":-360,"elapsed":14,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"88fa85ae-5908-4944-e8bd-e4ecc53f71df"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['distilgpt2',\n"," 'gpt2',\n"," 'davidkim205/komt-mistral-7b-v1',\n"," 'tiiuae/falcon-40b-instruct',\n"," 'bigscience/bloom-560m',\n"," 'meta-llama/Llama-2-7b-chat-hf',\n"," 'petals-team/StableBeluga2',\n"," 'facebook/opt-1.3b',\n"," 'HuggingFaceM4/tiny-random-LlamaForCausalLM',\n"," 'TheBloke/CodeLlama-34B-Instruct-GPTQ',\n"," 'facebook/opt-125m',\n"," 'microsoft/git-base',\n"," 'mistralai/Mistral-7B-Instruct-v0.1',\n"," 'mistralai/Mistral-7B-v0.1',\n"," 'meta-llama/Llama-2-7b-hf',\n"," 'TheBloke/Llama-2-7B-Chat-GPTQ',\n"," 'gpt2-medium',\n"," 'gpt2-large',\n"," 'NousResearch/Nous-Hermes-Llama2-13b',\n"," 'ehartford/Samantha-1.11-70b']"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","source":["## csv for classification model"],"metadata":{"id":"zIrKbNmfRzi5"}},{"cell_type":"markdown","source":["## csv for generative model"],"metadata":{"id":"rwv8_bNmR3cX"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","from huggingface_hub import HfApi\n","\n","# ... (your existing code)\n","\n","# Create a list to store model names and associated apps\n","generative_model_apps_list = []\n","\n","# Function to get the combined names for all apps associated with a model\n","def get_combined_names_for_model(generative_model_name):\n","    url = f\"https://huggingface.co/spaces?sort=likes&search={generative_model_name}\"\n","    response = requests.get(url)\n","\n","    if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","        try:\n","            html_content = response.text\n","            soup = BeautifulSoup(html_content, 'html.parser')\n","\n","            # Find all h4 elements with class \"z-40 max-w-full truncate text-center font-bold leading-tight text-blue-50 text-base\"\n","            h4_elements = soup.find_all('h4', class_='z-40 max-w-full truncate text-center font-bold leading-tight text-blue-50 text-base')\n","\n","            # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","            a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","            generative_combined_names = []\n","\n","            # Iterate through each pair of h4 and a elements and combine the names\n","            for h4_element, a_element in zip(h4_elements, a_elements):\n","                app_name = h4_element.text.strip()\n","                creator_name = a_element.text.strip()\n","                generative_combined_name = f\"{creator_name}/{app_name}\"\n","                generative_combined_names.append(generative_combined_name)\n","\n","            return generative_combined_names\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            return None\n","    else:\n","        print(f\"Error: {response.status_code} - {response.text}\")\n","        return None\n","\n","# Iterate through each model and get combined names for all apps\n","for generative_model_name in generative_model_names:\n","    generative_combined_names = get_combined_names_for_model(generative_model_name)\n","    if generative_combined_names:\n","        for generative_combined_name in generative_combined_names:\n","            generative_model_apps_list.append({'generative_Model': generative_model_name, 'Combined Name': generative_combined_name})\n","\n","# Save the data to a CSV file\n","csv_file_path = 'generative_model_apps.csv'\n","fieldnames = ['generative_Model', 'Combined Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(generative_model_apps_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model names and combined names.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIBbTW3rbXCz","executionInfo":{"status":"ok","timestamp":1702978974487,"user_tz":-360,"elapsed":9744,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"3e0635ff-3713-4c8a-a061-291f30653e1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'generative_model_apps.csv' has been created with model names and combined names.\n"]}]},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","from huggingface_hub import HfApi\n","\n","# Function to get the number of articles for a model\n","def get_num_articles(generative_model_name):\n","    url = f\"https://huggingface.co/spaces?sort=likes&search={generative_model_name}\"\n","    response = requests.get(url)\n","\n","    if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","        try:\n","            html_content = response.text\n","            soup = BeautifulSoup(html_content, 'html.parser')\n","\n","            # Find the div with class \"grid grid-cols-1 gap-x-4 gap-y-6 md:grid-cols-3 xl:grid-cols-4\"\n","            class_div = soup.find('div', class_='grid grid-cols-1 gap-x-4 gap-y-6 md:grid-cols-3 xl:grid-cols-4')\n","\n","            if class_div:\n","                # Find all articles under the div\n","                articles = class_div.find_all('article', class_='')\n","\n","                # Return the number of articles\n","                return len(articles)\n","            else:\n","                return 0\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            return 0\n","    else:\n","        print(f\"Error: {response.status_code} - {response.text}\")\n","        return 0\n","\n","# Function to get all models with a specific tag\n","def get_models_by_tag(tag):\n","    hf_api = HfApi(endpoint=\"https://huggingface.co\")\n","    all_models = hf_api.list_models()\n","    tag_models = [model for model in all_models if tag.lower() in [model_tag.lower() for model_tag in model.tags]]\n","    return tag_models\n","\n","# Create a list to store model and app details\n","model_app_details_list = []\n","\n","# Function to get the combined names for all apps associated with a model\n","def get_combined_names_for_model(generative_model_name):\n","    url = f\"https://huggingface.co/spaces?sort=likes&search={generative_model_name}\"\n","    response = requests.get(url)\n","\n","    if response.status_code == 200 and 'text/html' in response.headers['content-type']:\n","        try:\n","            html_content = response.text\n","            soup = BeautifulSoup(html_content, 'html.parser')\n","\n","            # Find all h4 elements with class \"z-40 max-w-full truncate text-center font-bold leading-tight text-blue-50 text-base\"\n","            h4_elements = soup.find_all('h4', class_='z-40 max-w-full truncate text-center font-bold leading-tight text-blue-50 text-base')\n","\n","            # Find all a elements with class \"truncate font-mono text-sm text-black\"\n","            a_elements = soup.find_all('a', class_='truncate font-mono text-sm text-black')\n","\n","            generative_combined_names = []\n","\n","            # Iterate through each pair of h4 and a elements and combine the names\n","            for h4_element, a_element in zip(h4_elements, a_elements):\n","                app_name = h4_element.text.strip()\n","                creator_name = a_element.text.strip()\n","                generative_combined_names.append({'App ID': creator_name, 'App Name': app_name})\n","\n","            return generative_combined_names\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","            return None\n","    else:\n","        print(f\"Error: {response.status_code} - {response.text}\")\n","        return None\n","\n","# Get all \"text classification\" models\n","text_generative_models = get_models_by_tag(\"text-generation\")\n","\n","# Sort models by downloads in descending order\n","text_generative_models_sorted = sorted(text_generative_models, key=lambda x: x.downloads, reverse=True)\n","\n","# Iterate through each model and get combined names for all apps\n","for model in text_generative_models_sorted[:20]:\n","    model_id = model.modelId\n","    model_name = model.modelId\n","    num_articles = get_num_articles(model.modelId)\n","    combined_names = get_combined_names_for_model(model.modelId)\n","\n","    if combined_names:\n","        for app_details in combined_names:\n","            app_details.update({'Model ID': model_id, 'Model Name': model_name})\n","            model_app_details_list.append(app_details)\n","\n","# Save the data to a CSV file\n","csv_file_path = 'generative_model_app_details.csv'\n","fieldnames = ['Model ID', 'Model Name', 'App ID', 'App Name']\n","\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    writer.writeheader()\n","    writer.writerows(model_app_details_list)\n","\n","print(f\"CSV file '{csv_file_path}' has been created with model and app details.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qa53vbI3-35T","executionInfo":{"status":"ok","timestamp":1702988007929,"user_tz":-360,"elapsed":44620,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"7cdb5aba-8fdd-4c9d-df20-53c022bf42f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file 'generative_model_app_details.csv' has been created with model and app details.\n"]}]},{"cell_type":"markdown","source":["# obtain and compare the source code size of the ML apps (\"spaces\") obtained in step 2 (HINT: check the \"Files\" tab at the top-right of a given space's page)"],"metadata":{"id":"U_1T8OCbPj9_"}},{"cell_type":"markdown","source":["## classification model apps size"],"metadata":{"id":"fR3NzsT2UYqW"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to extract size from HTML content\n","def get_size_from_html(html_content):\n","    soup = BeautifulSoup(html_content, 'html.parser')\n","    byte_sum = 0\n","    for tag in soup.find_all(text=True):\n","        if 'byte' in tag.lower():\n","            try:\n","                byte_value = int(tag.split()[0])\n","                byte_sum += byte_value\n","            except ValueError:\n","                pass\n","    return byte_sum\n","\n","# Function to fetch HTML content of a given URL\n","def get_html_content(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        return response.text\n","    else:\n","        return None\n","\n","# Read CSV file\n","csv_file_path = 'classification_model_apps.csv'  # Replace with the path to your CSV file\n","output_csv_file_path = 'classification_app_size.csv'  # New CSV file for app sizes\n","\n","with open(csv_file_path, 'r') as file, open(output_csv_file_path, 'w', newline='') as output_file:\n","    # Create CSV writer\n","    fieldnames = ['classification_Model', 'Combined Name', 'App Size (bytes)']\n","    writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n","\n","    # Write header to the output file\n","    writer.writeheader()\n","\n","    reader = csv.DictReader(file)\n","\n","    # Iterate through each row in the CSV\n","    for row in reader:\n","        model_name = row['classification_Model']\n","        combined_name = row['Combined Name']\n","\n","        # Replace spaces with dashes\n","        formatted_combined_name = combined_name.replace(' ', '-')\n","\n","        # Generate the URL\n","        url = f'https://huggingface.co/spaces/{formatted_combined_name}/tree/main'\n","        # print(url)\n","\n","        # Fetch HTML content\n","        html_content = get_html_content(url)\n","\n","        if html_content is not None:\n","            # Extract size from HTML\n","            app_size = get_size_from_html(html_content)\n","\n","            # Write to the output file\n","            writer.writerow({'classification_Model': model_name, 'Combined Name': combined_name, 'App Size (bytes)': app_size})\n","\n","            # Print or store the result as needed\n","            print(f'classification_Model: {model_name}, Combined Name: {combined_name}, App Size: {app_size} bytes')\n","        else:\n","            print(f'Error fetching content for Model: {model_name}, Combined Name: {combined_name}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qe3npcoiOPed","executionInfo":{"status":"ok","timestamp":1702979112314,"user_tz":-360,"elapsed":58188,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"02aae3ce-d80c-4928-ab5c-099f22e3eb46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-76-c3a43b0fa32d>:9: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n","  for tag in soup.find_all(text=True):\n"]},{"output_type":"stream","name":"stdout","text":["classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: DogManTC/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 1291 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: cmorato/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 370 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: rcuchoa/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 393 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: leolinardi/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 373 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: Offdutyninja/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 373 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: Jayod/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 375 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: RaoMuneeb/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 372 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: glrh11/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 716 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: wesley7137/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 373 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: asapjabber/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 375 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: ozxdisma/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 410 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: mahaanand/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 377 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: kaungmyat/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 371 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: alexpaul/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 372 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: alanbabygirl/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 362 bytes\n","classification_Model: distilbert-base-uncased-finetuned-sst-2-english, Combined Name: z0mz0m/Distilbert Base Uncased Finetuned Sst 2 English, App Size: 372 bytes\n","classification_Model: mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, Combined Name: Mavrck307/Mrm8488 Distilroberta Finetuned Financial News Sentiment Analysis, App Size: 409 bytes\n","classification_Model: mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, Combined Name: jboyerjr/Mrm8488 Distilroberta Finetuned Financial News Sentiment Analysis, App Size: 413 bytes\n","classification_Model: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli, Combined Name: happyhaplu/MoritzLaurer DeBERTa V3 Base Mnli Fever Anli, App Size: 367 bytes\n","classification_Model: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli, Combined Name: Jofthomas/MoritzLaurer DeBERTa V3 Base Mnli Fever Anli, App Size: 369 bytes\n","classification_Model: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli, Combined Name: Avatarofhemant/MoritzLaurer DeBERTa V3 Base Mnli Fever Anli, App Size: 366 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: 834188divi/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: FrancescoBerg/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: dajayk12/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: Daniton/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: Daniton/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: quni/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 390 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: msalazark/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 370 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: alpha-hp/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 376 bytes\n","Error fetching content for Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: xingxing12/Cardiffnlp Twitter Roberta Base Sentiment Latest\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: bobrooos/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: zox47/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 367 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: zox47/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 367 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: psycen/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 366 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: 834188divi/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","Error fetching content for Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: asungajinli/Cardiffnlp Twitter Roberta Base Sentiment Latest Gradio\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: TestSpace/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 378 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: TestSpace/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 378 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: salmanmoh/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 391 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: 10isha/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 372 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: sotirios-slv/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: Fatima33/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment, Combined Name: data2science/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: facebook/bart-large-mnli, Combined Name: awacke1/ZeroShotClassifiers Facebook Bart Large Mnli, App Size: 360 bytes\n","classification_Model: facebook/bart-large-mnli, Combined Name: awacke1/Zero Shot Classification Facebook Bart Large Mnli, App Size: 362 bytes\n","classification_Model: facebook/bart-large-mnli, Combined Name: awacke1/Easy Button Zero Shot Text Classifier Facebook Bart Large Mnli, App Size: 379 bytes\n","Error fetching content for Model: facebook/bart-large-mnli, Combined Name: srikotha/Easy Button Zero Shot Text Classifier Facebook Bart Large Mnli\n","classification_Model: facebook/bart-large-mnli, Combined Name: ceckenrode/Easy Button Zero Shot Text Classifier Facebook Bart Large Mnli, App Size: 380 bytes\n","Error fetching content for Model: facebook/bart-large-mnli, Combined Name: JSanchez79/Zeroshot Classifire Facebook Bart Large Mnli\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: 834188divi/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: FrancescoBerg/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: dajayk12/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: Daniton/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: Daniton/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: quni/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 390 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: alpha-hp/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 376 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: bobrooos/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: zox47/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: TestSpace/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 378 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: TestSpace/Cardiffnlp Twitter Roberta Base Sentiment Latest Gradio, App Size: 381 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: salmanmoh/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 391 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: 10isha/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 372 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: sotirios-slv/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 373 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: Fatima33/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: data2science/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 375 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: wsaults/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 393 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: dx1/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 372 bytes\n","classification_Model: cardiffnlp/twitter-roberta-base-sentiment-latest, Combined Name: farooq-09/Cardiffnlp Twitter Roberta Base Sentiment Latest, App Size: 393 bytes\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, Combined Name: joey1895/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 407 bytes\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, Combined Name: alexanderander30/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 374 bytes\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, Combined Name: Abdel/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 373 bytes\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, Combined Name: Sowmya1022/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 376 bytes\n","classification_Model: nlptown/bert-base-multilingual-uncased-sentiment, Combined Name: ans123/Nlptown Bert Base Multilingual Uncased Sentiment, App Size: 374 bytes\n","classification_Model: cardiffnlp/twitter-xlm-roberta-base-sentiment, Combined Name: msalazark/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 370 bytes\n","classification_Model: cardiffnlp/twitter-xlm-roberta-base-sentiment, Combined Name: zox47/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 367 bytes\n","classification_Model: cardiffnlp/twitter-xlm-roberta-base-sentiment, Combined Name: psycen/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 366 bytes\n","classification_Model: cardiffnlp/twitter-xlm-roberta-base-sentiment, Combined Name: 834188divi/Cardiffnlp Twitter Xlm Roberta Base Sentiment, App Size: 371 bytes\n"]}]},{"cell_type":"markdown","source":["## generative model apps size"],"metadata":{"id":"I7Y9oerPVms4"}},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to extract size from HTML content\n","def get_size_from_html(html_content):\n","    soup = BeautifulSoup(html_content, 'html.parser')\n","    byte_sum = 0\n","    for tag in soup.find_all(text=True):\n","        if 'byte' in tag.lower():\n","            try:\n","                byte_value = int(tag.split()[0])\n","                byte_sum += byte_value\n","            except ValueError:\n","                pass\n","    return byte_sum\n","\n","# Function to fetch HTML content of a given URL\n","def get_html_content(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        return response.text\n","    else:\n","        return None\n","\n","# Read CSV file\n","csv_file_path = 'generative_model_apps.csv'  # Replace with the path to your CSV file\n","output_csv_file_path = 'generative_app_size.csv'  # New CSV file for app sizes\n","\n","with open(csv_file_path, 'r') as file, open(output_csv_file_path, 'w', newline='') as output_file:\n","    # Create CSV writer\n","    fieldnames = ['generative_Model', 'Combined Name', 'App Size (bytes)']\n","    writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n","\n","    # Write header to the output file\n","    writer.writeheader()\n","\n","    reader = csv.DictReader(file)\n","\n","    # Iterate through each row in the CSV\n","    for row in reader:\n","        model_name = row['generative_Model']\n","        combined_name = row['Combined Name']\n","\n","        # Replace spaces with dashes\n","        formatted_combined_name = combined_name.replace(' ', '-')\n","\n","        # Generate the URL\n","        url = f'https://huggingface.co/spaces/{formatted_combined_name}/tree/main'\n","        print(url)\n","\n","        # Fetch HTML content\n","        html_content = get_html_content(url)\n","\n","        if html_content is not None:\n","            # Extract size from HTML\n","            app_size = get_size_from_html(html_content)\n","\n","            # Write to the output file\n","            writer.writerow({'generative_Model': model_name, 'Combined Name': combined_name, 'App Size (bytes)': app_size})\n","\n","            # Print or store the result as needed\n","            print(f'generative_Model: {model_name}, Combined Name: {combined_name}, App Size: {app_size} bytes')\n","        else:\n","            print(f'Error fetching content for Model: {model_name}, Combined Name: {combined_name}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0phZT0BVtQH","executionInfo":{"status":"ok","timestamp":1702979164924,"user_tz":-360,"elapsed":2079,"user":{"displayName":"SAMIUL ISLAM, 180041221","userId":"11805475344626590709"}},"outputId":"7adcb2da-9c80-47f4-880c-a77136c02f72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://huggingface.co/spaces/Norod78/Shibing624-Code-Autocomplete-Distilgpt2-Python/tree/main\n","Error fetching content for Model: distilgpt2, Combined Name: Norod78/Shibing624 Code Autocomplete Distilgpt2 Python\n","https://huggingface.co/spaces/ICML2022/DunnBC22-distilgpt2-2k-Clean-Medical-Articles-Causal-Language-Model/tree/main\n","Error fetching content for Model: distilgpt2, Combined Name: ICML2022/DunnBC22-distilgpt2-2k Clean Medical Articles Causal Language Model\n","https://huggingface.co/spaces/Rexuint/Aman-mehra-gpt2-medium-finetune-squad-ep-2.5-lr-3e-06-wd-0.0002-glb-Sd-1-data-Sd-0/tree/main\n","Error fetching content for Model: gpt2-medium, Combined Name: Rexuint/Aman-mehra-gpt2-medium-finetune-squad-ep-2.5-lr-3e-06-wd-0.0002-glb Sd-1-data Sd-0\n","https://huggingface.co/spaces/heegyu/Caseyhahn-Gpt2-Medium-Finetuned-Genius-Lyrics-Updated-Data-Large/tree/main\n","Error fetching content for Model: gpt2-medium, Combined Name: heegyu/Caseyhahn Gpt2 Medium Finetuned Genius Lyrics Updated Data Large\n","https://huggingface.co/spaces/innev/Caseyhahn-Gpt2-Medium-Finetuned-Genius-Lyrics-Updated-Data-Large/tree/main\n","Error fetching content for Model: gpt2-large, Combined Name: innev/Caseyhahn Gpt2 Medium Finetuned Genius Lyrics Updated Data Large\n"]}]}]}